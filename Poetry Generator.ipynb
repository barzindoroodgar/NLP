{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Poetry using an LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.utils as ku \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2690\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "data = open('data/sonnets.txt').read()\n",
    "\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input sequences using list of tokens\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create x-values (padded sequence fed in NN) and label (the next token in sequence expected)\n",
    "xs, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "# on-hot-encode the label \n",
    "ys = ku.to_categorical(label, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'come all ye maidens young and fair'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2, 11, 15],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 15, 100)           269000    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 15, 300)           301200    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1345)              135845    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2690)              3620740   \n",
      "=================================================================\n",
      "Total params: 4,487,185\n",
      "Trainable params: 4,487,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12038 samples\n",
      "Epoch 1/300\n",
      "12038/12038 [==============================] - 68s 6ms/sample - loss: 6.8106 - accuracy: 0.0636\n",
      "Epoch 2/300\n",
      "12038/12038 [==============================] - 50s 4ms/sample - loss: 6.3215 - accuracy: 0.0657\n",
      "Epoch 3/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 6.1731 - accuracy: 0.0676\n",
      "Epoch 4/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 6.0339 - accuracy: 0.0759\n",
      "Epoch 5/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 5.9365 - accuracy: 0.0821\n",
      "Epoch 6/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 5.8353 - accuracy: 0.0891\n",
      "Epoch 7/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 5.7301 - accuracy: 0.0961\n",
      "Epoch 8/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 5.6342 - accuracy: 0.1033\n",
      "Epoch 9/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 5.5500 - accuracy: 0.1082\n",
      "Epoch 10/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 5.4684 - accuracy: 0.1106\n",
      "Epoch 11/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 5.3957 - accuracy: 0.1145\n",
      "Epoch 12/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 5.3321 - accuracy: 0.1200\n",
      "Epoch 13/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 5.2698 - accuracy: 0.1242\n",
      "Epoch 14/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 5.2090 - accuracy: 0.1266\n",
      "Epoch 15/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 5.1512 - accuracy: 0.1277\n",
      "Epoch 16/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 5.0931 - accuracy: 0.1307\n",
      "Epoch 17/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 5.0292 - accuracy: 0.1327\n",
      "Epoch 18/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 4.9680 - accuracy: 0.1349\n",
      "Epoch 19/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 4.9062 - accuracy: 0.1376\n",
      "Epoch 20/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 4.8520 - accuracy: 0.1406\n",
      "Epoch 21/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 4.7941 - accuracy: 0.1454\n",
      "Epoch 22/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 4.7263 - accuracy: 0.1498\n",
      "Epoch 23/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 4.6688 - accuracy: 0.1545\n",
      "Epoch 24/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 4.6028 - accuracy: 0.1584\n",
      "Epoch 25/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 4.5498 - accuracy: 0.1629\n",
      "Epoch 26/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 4.4852 - accuracy: 0.1691\n",
      "Epoch 27/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 4.4246 - accuracy: 0.1766\n",
      "Epoch 28/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 4.3693 - accuracy: 0.1784\n",
      "Epoch 29/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 4.3151 - accuracy: 0.1852\n",
      "Epoch 30/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 4.2588 - accuracy: 0.1918\n",
      "Epoch 31/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 4.1958 - accuracy: 0.1954\n",
      "Epoch 32/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 4.1360 - accuracy: 0.2061\n",
      "Epoch 33/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 4.0816 - accuracy: 0.2100\n",
      "Epoch 34/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 4.0247 - accuracy: 0.2199\n",
      "Epoch 35/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 3.9709 - accuracy: 0.2241\n",
      "Epoch 36/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 3.9145 - accuracy: 0.2309\n",
      "Epoch 37/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 3.8621 - accuracy: 0.2387\n",
      "Epoch 38/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 3.7995 - accuracy: 0.2484\n",
      "Epoch 39/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 3.7500 - accuracy: 0.2539\n",
      "Epoch 40/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 3.7009 - accuracy: 0.2659\n",
      "Epoch 41/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 3.6528 - accuracy: 0.2727\n",
      "Epoch 42/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 3.6012 - accuracy: 0.2798\n",
      "Epoch 43/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 3.5475 - accuracy: 0.2924\n",
      "Epoch 44/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 3.4985 - accuracy: 0.3023\n",
      "Epoch 45/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 3.4608 - accuracy: 0.3052\n",
      "Epoch 46/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 3.4046 - accuracy: 0.3199\n",
      "Epoch 47/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 3.3559 - accuracy: 0.3300\n",
      "Epoch 48/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 3.3064 - accuracy: 0.3403\n",
      "Epoch 49/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 3.2703 - accuracy: 0.3454\n",
      "Epoch 50/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 3.2248 - accuracy: 0.3563\n",
      "Epoch 51/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 3.1781 - accuracy: 0.3668\n",
      "Epoch 52/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 3.1405 - accuracy: 0.3737\n",
      "Epoch 53/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 3.0896 - accuracy: 0.3857\n",
      "Epoch 54/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 3.0557 - accuracy: 0.3922\n",
      "Epoch 55/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 3.0130 - accuracy: 0.4011\n",
      "Epoch 56/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.9775 - accuracy: 0.4068\n",
      "Epoch 57/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.9462 - accuracy: 0.4116\n",
      "Epoch 58/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.8981 - accuracy: 0.4272\n",
      "Epoch 59/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.8558 - accuracy: 0.4345\n",
      "Epoch 60/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.8246 - accuracy: 0.4415\n",
      "Epoch 61/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.7880 - accuracy: 0.4526\n",
      "Epoch 62/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 2.7456 - accuracy: 0.4651\n",
      "Epoch 63/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.7124 - accuracy: 0.4698\n",
      "Epoch 64/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.6801 - accuracy: 0.4770\n",
      "Epoch 65/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.6490 - accuracy: 0.4831\n",
      "Epoch 66/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 2.6170 - accuracy: 0.4885\n",
      "Epoch 67/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.5810 - accuracy: 0.4961\n",
      "Epoch 68/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.5472 - accuracy: 0.5032\n",
      "Epoch 69/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.5203 - accuracy: 0.5177\n",
      "Epoch 70/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.4932 - accuracy: 0.5169\n",
      "Epoch 71/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.4683 - accuracy: 0.5228\n",
      "Epoch 72/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.4348 - accuracy: 0.5316\n",
      "Epoch 73/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.3967 - accuracy: 0.5430\n",
      "Epoch 74/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.3673 - accuracy: 0.5493\n",
      "Epoch 75/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 2.3440 - accuracy: 0.5502\n",
      "Epoch 76/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.3288 - accuracy: 0.5519\n",
      "Epoch 77/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.2858 - accuracy: 0.5672\n",
      "Epoch 78/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.2749 - accuracy: 0.5703\n",
      "Epoch 79/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.2402 - accuracy: 0.5749\n",
      "Epoch 80/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 2.2035 - accuracy: 0.5858\n",
      "Epoch 81/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.1838 - accuracy: 0.5944\n",
      "Epoch 82/300\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 2.1538 - accuracy: 0.5967\n",
      "Epoch 83/300\n",
      "12038/12038 [==============================] - 52s 4ms/sample - loss: 2.1509 - accuracy: 0.5950\n",
      "Epoch 84/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 2.1182 - accuracy: 0.6012\n",
      "Epoch 85/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 2.0960 - accuracy: 0.6061\n",
      "Epoch 86/300\n",
      "12038/12038 [==============================] - 52s 4ms/sample - loss: 2.0699 - accuracy: 0.6143\n",
      "Epoch 87/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 2.0453 - accuracy: 0.6198\n",
      "Epoch 88/300\n",
      "12038/12038 [==============================] - 50s 4ms/sample - loss: 2.0290 - accuracy: 0.6199\n",
      "Epoch 89/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 2.0163 - accuracy: 0.6210\n",
      "Epoch 90/300\n",
      "12038/12038 [==============================] - 52s 4ms/sample - loss: 1.9758 - accuracy: 0.6367\n",
      "Epoch 91/300\n",
      "12038/12038 [==============================] - 54s 4ms/sample - loss: 1.9677 - accuracy: 0.6362\n",
      "Epoch 92/300\n",
      "12038/12038 [==============================] - 56s 5ms/sample - loss: 1.9471 - accuracy: 0.6396\n",
      "Epoch 93/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 1.9298 - accuracy: 0.6409\n",
      "Epoch 94/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 1.9064 - accuracy: 0.6474\n",
      "Epoch 95/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 1.8939 - accuracy: 0.6497\n",
      "Epoch 96/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 1.8692 - accuracy: 0.6517\n",
      "Epoch 97/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 1.8559 - accuracy: 0.6599\n",
      "Epoch 98/300\n",
      "12038/12038 [==============================] - 51s 4ms/sample - loss: 1.8420 - accuracy: 0.6582\n",
      "Epoch 99/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.8203 - accuracy: 0.6657\n",
      "Epoch 100/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.7896 - accuracy: 0.6707\n",
      "Epoch 101/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.7779 - accuracy: 0.6717\n",
      "Epoch 102/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.7616 - accuracy: 0.6762\n",
      "Epoch 103/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.7403 - accuracy: 0.6853\n",
      "Epoch 104/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.7284 - accuracy: 0.6860\n",
      "Epoch 105/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.7169 - accuracy: 0.6862\n",
      "Epoch 106/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.6967 - accuracy: 0.6902\n",
      "Epoch 107/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.6922 - accuracy: 0.6916\n",
      "Epoch 108/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.6689 - accuracy: 0.6949\n",
      "Epoch 109/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.6487 - accuracy: 0.7006\n",
      "Epoch 110/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.6434 - accuracy: 0.6985\n",
      "Epoch 111/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.6299 - accuracy: 0.7041\n",
      "Epoch 112/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.6111 - accuracy: 0.7055\n",
      "Epoch 113/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.6061 - accuracy: 0.7083\n",
      "Epoch 114/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.5897 - accuracy: 0.7096\n",
      "Epoch 115/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.5769 - accuracy: 0.7147\n",
      "Epoch 116/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.5686 - accuracy: 0.7142\n",
      "Epoch 117/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.5591 - accuracy: 0.7166\n",
      "Epoch 118/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.5379 - accuracy: 0.7243\n",
      "Epoch 119/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.5267 - accuracy: 0.7221\n",
      "Epoch 120/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.5173 - accuracy: 0.7217\n",
      "Epoch 121/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.5269 - accuracy: 0.7239\n",
      "Epoch 122/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.4948 - accuracy: 0.7308\n",
      "Epoch 123/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.4877 - accuracy: 0.7294\n",
      "Epoch 124/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.4609 - accuracy: 0.7351\n",
      "Epoch 125/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.4579 - accuracy: 0.7356\n",
      "Epoch 126/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.4389 - accuracy: 0.7411\n",
      "Epoch 127/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.4289 - accuracy: 0.7415\n",
      "Epoch 128/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.4321 - accuracy: 0.7398\n",
      "Epoch 129/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.4208 - accuracy: 0.7433\n",
      "Epoch 130/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.3979 - accuracy: 0.7486\n",
      "Epoch 131/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.3924 - accuracy: 0.7496\n",
      "Epoch 132/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.3876 - accuracy: 0.7527\n",
      "Epoch 133/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.3841 - accuracy: 0.7486\n",
      "Epoch 134/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.3674 - accuracy: 0.7556\n",
      "Epoch 135/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.3588 - accuracy: 0.7549\n",
      "Epoch 136/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.3464 - accuracy: 0.7569\n",
      "Epoch 137/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.3405 - accuracy: 0.7554\n",
      "Epoch 138/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.3380 - accuracy: 0.7589\n",
      "Epoch 139/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.3162 - accuracy: 0.7601\n",
      "Epoch 140/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.3137 - accuracy: 0.7584\n",
      "Epoch 141/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.3176 - accuracy: 0.7608\n",
      "Epoch 142/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.2955 - accuracy: 0.7673\n",
      "Epoch 143/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.2835 - accuracy: 0.7652\n",
      "Epoch 144/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.2750 - accuracy: 0.7744\n",
      "Epoch 145/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.2689 - accuracy: 0.7701\n",
      "Epoch 146/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.2537 - accuracy: 0.7728\n",
      "Epoch 147/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.2592 - accuracy: 0.7731\n",
      "Epoch 148/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.2620 - accuracy: 0.7733\n",
      "Epoch 149/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 1.2518 - accuracy: 0.7739\n",
      "Epoch 150/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.2384 - accuracy: 0.7761\n",
      "Epoch 151/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.2332 - accuracy: 0.7770\n",
      "Epoch 152/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 1.2265 - accuracy: 0.7770\n",
      "Epoch 153/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 1.2105 - accuracy: 0.7819\n",
      "Epoch 154/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.2112 - accuracy: 0.7821\n",
      "Epoch 155/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.1935 - accuracy: 0.7843\n",
      "Epoch 156/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.1825 - accuracy: 0.7858\n",
      "Epoch 157/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 1.1888 - accuracy: 0.7876\n",
      "Epoch 158/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 1.1824 - accuracy: 0.7893\n",
      "Epoch 159/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.1656 - accuracy: 0.7946\n",
      "Epoch 160/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 1.1727 - accuracy: 0.7895\n",
      "Epoch 161/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.1742 - accuracy: 0.7862\n",
      "Epoch 162/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.1642 - accuracy: 0.7888\n",
      "Epoch 163/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.1463 - accuracy: 0.7944\n",
      "Epoch 164/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 1.1343 - accuracy: 0.7957\n",
      "Epoch 165/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.1323 - accuracy: 0.7947\n",
      "Epoch 166/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.1291 - accuracy: 0.7976\n",
      "Epoch 167/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.1274 - accuracy: 0.7986\n",
      "Epoch 168/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.1309 - accuracy: 0.7955\n",
      "Epoch 169/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.1206 - accuracy: 0.7961\n",
      "Epoch 170/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.1117 - accuracy: 0.7995\n",
      "Epoch 171/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.0943 - accuracy: 0.8050\n",
      "Epoch 172/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.0910 - accuracy: 0.8049\n",
      "Epoch 173/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.1066 - accuracy: 0.8000\n",
      "Epoch 174/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.0791 - accuracy: 0.8049\n",
      "Epoch 175/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.0819 - accuracy: 0.8048\n",
      "Epoch 176/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.0796 - accuracy: 0.8035\n",
      "Epoch 177/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.0797 - accuracy: 0.8035\n",
      "Epoch 178/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.0709 - accuracy: 0.8075\n",
      "Epoch 179/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.0491 - accuracy: 0.8117\n",
      "Epoch 180/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.0525 - accuracy: 0.8110\n",
      "Epoch 181/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.0562 - accuracy: 0.8118\n",
      "Epoch 182/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.0557 - accuracy: 0.8074\n",
      "Epoch 183/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.0470 - accuracy: 0.8089\n",
      "Epoch 184/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.0316 - accuracy: 0.8153\n",
      "Epoch 185/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.0319 - accuracy: 0.8111\n",
      "Epoch 186/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.0194 - accuracy: 0.8174\n",
      "Epoch 187/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.0285 - accuracy: 0.8138\n",
      "Epoch 188/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 1.0253 - accuracy: 0.8118\n",
      "Epoch 189/300\n",
      "12038/12038 [==============================] - 53s 4ms/sample - loss: 1.0295 - accuracy: 0.8124\n",
      "Epoch 190/300\n",
      "12038/12038 [==============================] - 51s 4ms/sample - loss: 1.0169 - accuracy: 0.8138\n",
      "Epoch 191/300\n",
      "12038/12038 [==============================] - 60s 5ms/sample - loss: 1.0045 - accuracy: 0.8182\n",
      "Epoch 192/300\n",
      "12038/12038 [==============================] - 57s 5ms/sample - loss: 0.9984 - accuracy: 0.8193\n",
      "Epoch 193/300\n",
      "12038/12038 [==============================] - 53s 4ms/sample - loss: 1.0011 - accuracy: 0.8190\n",
      "Epoch 194/300\n",
      "12038/12038 [==============================] - 50s 4ms/sample - loss: 1.0043 - accuracy: 0.8153\n",
      "Epoch 195/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 0.9981 - accuracy: 0.8159\n",
      "Epoch 196/300\n",
      "12038/12038 [==============================] - 50s 4ms/sample - loss: 0.9914 - accuracy: 0.8177\n",
      "Epoch 197/300\n",
      "12038/12038 [==============================] - 53s 4ms/sample - loss: 0.9849 - accuracy: 0.8216\n",
      "Epoch 198/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.9870 - accuracy: 0.8183\n",
      "Epoch 199/300\n",
      "12038/12038 [==============================] - 50s 4ms/sample - loss: 0.9775 - accuracy: 0.8209\n",
      "Epoch 200/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.9655 - accuracy: 0.8219\n",
      "Epoch 201/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.9642 - accuracy: 0.8248\n",
      "Epoch 202/300\n",
      "12038/12038 [==============================] - 52s 4ms/sample - loss: 0.9779 - accuracy: 0.8165\n",
      "Epoch 203/300\n",
      "12038/12038 [==============================] - 51s 4ms/sample - loss: 0.9671 - accuracy: 0.8216\n",
      "Epoch 204/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.9623 - accuracy: 0.8240\n",
      "Epoch 205/300\n",
      "12038/12038 [==============================] - 66s 5ms/sample - loss: 0.9599 - accuracy: 0.8215\n",
      "Epoch 206/300\n",
      "12038/12038 [==============================] - 54s 4ms/sample - loss: 0.9396 - accuracy: 0.8315\n",
      "Epoch 207/300\n",
      "12038/12038 [==============================] - 58s 5ms/sample - loss: 0.9507 - accuracy: 0.8257\n",
      "Epoch 208/300\n",
      "12038/12038 [==============================] - 52s 4ms/sample - loss: 0.9483 - accuracy: 0.8250\n",
      "Epoch 209/300\n",
      "12038/12038 [==============================] - 50s 4ms/sample - loss: 0.9472 - accuracy: 0.8258\n",
      "Epoch 210/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.9366 - accuracy: 0.8266\n",
      "Epoch 211/300\n",
      "12038/12038 [==============================] - 55s 5ms/sample - loss: 0.9304 - accuracy: 0.8287\n",
      "Epoch 212/300\n",
      "12038/12038 [==============================] - 54s 4ms/sample - loss: 0.9427 - accuracy: 0.8251\n",
      "Epoch 213/300\n",
      "12038/12038 [==============================] - 52s 4ms/sample - loss: 0.9384 - accuracy: 0.8264\n",
      "Epoch 214/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 0.9276 - accuracy: 0.8282\n",
      "Epoch 215/300\n",
      "12038/12038 [==============================] - 50s 4ms/sample - loss: 0.9149 - accuracy: 0.8305\n",
      "Epoch 216/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 0.9272 - accuracy: 0.8268\n",
      "Epoch 217/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 0.9307 - accuracy: 0.8254\n",
      "Epoch 218/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 0.9213 - accuracy: 0.8266\n",
      "Epoch 219/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 0.9186 - accuracy: 0.8280\n",
      "Epoch 220/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 0.9125 - accuracy: 0.8295\n",
      "Epoch 221/300\n",
      "12038/12038 [==============================] - 51s 4ms/sample - loss: 0.9091 - accuracy: 0.8315\n",
      "Epoch 222/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.9082 - accuracy: 0.8274\n",
      "Epoch 223/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.9001 - accuracy: 0.8334\n",
      "Epoch 224/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.9022 - accuracy: 0.8320\n",
      "Epoch 225/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 0.9025 - accuracy: 0.8297\n",
      "Epoch 226/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8979 - accuracy: 0.8330\n",
      "Epoch 227/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8948 - accuracy: 0.8314\n",
      "Epoch 228/300\n",
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 0.8960 - accuracy: 0.8290\n",
      "Epoch 229/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8953 - accuracy: 0.8312\n",
      "Epoch 230/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8835 - accuracy: 0.8348\n",
      "Epoch 231/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8815 - accuracy: 0.8339\n",
      "Epoch 232/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8810 - accuracy: 0.8343\n",
      "Epoch 233/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8796 - accuracy: 0.8353\n",
      "Epoch 234/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8777 - accuracy: 0.8338\n",
      "Epoch 235/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8688 - accuracy: 0.8366\n",
      "Epoch 236/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8709 - accuracy: 0.8329\n",
      "Epoch 237/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8749 - accuracy: 0.8347\n",
      "Epoch 238/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8704 - accuracy: 0.8367\n",
      "Epoch 239/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8705 - accuracy: 0.8329\n",
      "Epoch 240/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8619 - accuracy: 0.8388\n",
      "Epoch 241/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8556 - accuracy: 0.8387\n",
      "Epoch 242/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8604 - accuracy: 0.8353\n",
      "Epoch 243/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8623 - accuracy: 0.8329\n",
      "Epoch 244/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8592 - accuracy: 0.8354\n",
      "Epoch 245/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8483 - accuracy: 0.8379\n",
      "Epoch 246/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8571 - accuracy: 0.8334\n",
      "Epoch 247/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8517 - accuracy: 0.8359\n",
      "Epoch 248/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.8465 - accuracy: 0.8378\n",
      "Epoch 249/300\n",
      "12038/12038 [==============================] - 51s 4ms/sample - loss: 0.8538 - accuracy: 0.8379\n",
      "Epoch 250/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 0.8475 - accuracy: 0.8360\n",
      "Epoch 251/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 0.8412 - accuracy: 0.8387\n",
      "Epoch 252/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 0.8338 - accuracy: 0.8395\n",
      "Epoch 253/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 0.8384 - accuracy: 0.8383\n",
      "Epoch 254/300\n",
      "12038/12038 [==============================] - 49s 4ms/sample - loss: 0.8422 - accuracy: 0.8353\n",
      "Epoch 255/300\n",
      "12038/12038 [==============================] - 51s 4ms/sample - loss: 0.8337 - accuracy: 0.8393\n",
      "Epoch 256/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8357 - accuracy: 0.8374\n",
      "Epoch 257/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8438 - accuracy: 0.8384\n",
      "Epoch 258/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8393 - accuracy: 0.8347\n",
      "Epoch 259/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8325 - accuracy: 0.8378\n",
      "Epoch 260/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8209 - accuracy: 0.8403\n",
      "Epoch 261/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8184 - accuracy: 0.8403\n",
      "Epoch 262/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8199 - accuracy: 0.8418\n",
      "Epoch 263/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8200 - accuracy: 0.8413\n",
      "Epoch 264/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8284 - accuracy: 0.8383\n",
      "Epoch 265/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8213 - accuracy: 0.8393\n",
      "Epoch 266/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8199 - accuracy: 0.8422\n",
      "Epoch 267/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8132 - accuracy: 0.8394\n",
      "Epoch 268/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8187 - accuracy: 0.8404\n",
      "Epoch 269/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8049 - accuracy: 0.8411\n",
      "Epoch 270/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8151 - accuracy: 0.8398\n",
      "Epoch 271/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8071 - accuracy: 0.8421\n",
      "Epoch 272/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8053 - accuracy: 0.8406\n",
      "Epoch 273/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8025 - accuracy: 0.8424\n",
      "Epoch 274/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8014 - accuracy: 0.8422\n",
      "Epoch 275/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8091 - accuracy: 0.8408\n",
      "Epoch 276/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.7982 - accuracy: 0.8422\n",
      "Epoch 277/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8005 - accuracy: 0.8400\n",
      "Epoch 278/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8070 - accuracy: 0.8400\n",
      "Epoch 279/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8078 - accuracy: 0.8398\n",
      "Epoch 280/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8003 - accuracy: 0.8416\n",
      "Epoch 281/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8038 - accuracy: 0.8431\n",
      "Epoch 282/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.8098 - accuracy: 0.8400\n",
      "Epoch 283/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.7951 - accuracy: 0.8448\n",
      "Epoch 284/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.7867 - accuracy: 0.8418\n",
      "Epoch 285/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.7811 - accuracy: 0.8434\n",
      "Epoch 286/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.7904 - accuracy: 0.8426\n",
      "Epoch 287/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.7883 - accuracy: 0.8440\n",
      "Epoch 288/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.7799 - accuracy: 0.8446\n",
      "Epoch 289/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.7937 - accuracy: 0.8407\n",
      "Epoch 290/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.7874 - accuracy: 0.8432\n",
      "Epoch 291/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.7797 - accuracy: 0.8442\n",
      "Epoch 292/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.7797 - accuracy: 0.8455\n",
      "Epoch 293/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.7945 - accuracy: 0.8398\n",
      "Epoch 294/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.7799 - accuracy: 0.8430\n",
      "Epoch 295/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.7846 - accuracy: 0.8409\n",
      "Epoch 296/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.7901 - accuracy: 0.8416\n",
      "Epoch 297/300\n",
      "12038/12038 [==============================] - 48s 4ms/sample - loss: 0.7778 - accuracy: 0.8419\n",
      "Epoch 298/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12038/12038 [==============================] - 46s 4ms/sample - loss: 0.7806 - accuracy: 0.8412\n",
      "Epoch 299/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.7737 - accuracy: 0.8467\n",
      "Epoch 300/300\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.7681 - accuracy: 0.8435\n"
     ]
    }
   ],
   "source": [
    " history = model.fit(xs, ys, epochs=300, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help me Obi Wan Kenobi, you're my only hope i took on a lad that no hiii died of that had i cant remember when writin a wish my love young and low away behind from your eyes glisten are sweetly dearly fresh as the banks of the bay that do her roses my pale friend a girl i might meet below over the broad majestic shannon she gave me her hope and play there i was my father died and made him a man saw she said mine the begging id the stars of mooncoin all one was over gilgarra mountain loved me old wild today of its\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/barzin/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: saved_model/poetry_gen_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/poetry_gen_model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poetry_gen_model\n",
      "assets\tsaved_model.pb\tvariables\n"
     ]
    }
   ],
   "source": [
    "# my_model directory\n",
    "!ls saved_model\n",
    "\n",
    "# Contains an assets folder, saved_model.pb, and variables folder.\n",
    "!ls saved_model/poetry_gen_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "new_model = load_model('saved_model/poetry_gen_model')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me a boat that can carry two agin again away by his hair but volunteers thy eyes roses all all the street on that a stroll all among the quality gardens with liffey and the broad majestic shannon their mantle that beaming smile laughing went to me my day love wind wind under their real love the fields down of the day fair white song wind ones hair with bright green sea love so smiling wish me father love love love the banks of the day young days of her journey to doneen not fresh and me new land of me glass\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Give me a\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = new_model.predict_classes(token_list, verbose=0)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12038 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['bidirectional_2/forward_lstm_4/kernel:0', 'bidirectional_2/forward_lstm_4/recurrent_kernel:0', 'bidirectional_2/forward_lstm_4/bias:0', 'bidirectional_2/backward_lstm_4/kernel:0', 'bidirectional_2/backward_lstm_4/recurrent_kernel:0', 'bidirectional_2/backward_lstm_4/bias:0', 'lstm_5/kernel:0', 'lstm_5/recurrent_kernel:0', 'lstm_5/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['bidirectional_2/forward_lstm_4/kernel:0', 'bidirectional_2/forward_lstm_4/recurrent_kernel:0', 'bidirectional_2/forward_lstm_4/bias:0', 'bidirectional_2/backward_lstm_4/kernel:0', 'bidirectional_2/backward_lstm_4/recurrent_kernel:0', 'bidirectional_2/backward_lstm_4/bias:0', 'lstm_5/kernel:0', 'lstm_5/recurrent_kernel:0', 'lstm_5/bias:0'] when minimizing the loss.\n",
      "12038/12038 [==============================] - 52s 4ms/sample - loss: 0.7754 - accuracy: 0.8475\n",
      "Epoch 2/5\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.7523 - accuracy: 0.8483\n",
      "Epoch 3/5\n",
      "12038/12038 [==============================] - 47s 4ms/sample - loss: 0.7435 - accuracy: 0.8486\n",
      "Epoch 4/5\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 0.7417 - accuracy: 0.8508\n",
      "Epoch 5/5\n",
      "12038/12038 [==============================] - 45s 4ms/sample - loss: 0.7437 - accuracy: 0.8486\n"
     ]
    }
   ],
   "source": [
    "# training the model will pick up where it left off... \n",
    "history = new_model.fit(xs, ys, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
